---
{"dg-publish":true,"dg-path":"Sycophantic LLMs.md","permalink":"/sycophantic-ll-ms/","title":"Sycophantic LLMs"}
---


<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">




ğŸ  [[public/Index\|home]]  â‹® ğŸ—£ï¸ [[public/all-blips\|blips]] â‹®  ğŸ“ [[public/All Articles\|articles]]  â‹® ğŸ•°ï¸ [[public/now\|now]]


</div></div>


# Sycophantic LLMs
<p><span>ğŸ“† <code>Thursday, May 1, 2025</code></span></p>
#AI #LLM

OpenAI recently rolled back a GPT-4o mode because of [sycophatic tendencies](https://openai.com/index/sycophancy-in-gpt-4o/) . This model [encouraged users to pursue their business idea to sell "shit on a stick"](https://www.reddit.com/r/ChatGPT/comments/1k920cg/new_chatgpt_just_told_me_my_literal_shit_on_a/) or expressed strong support when someone [told it that they stopped taking their meds and embarked on a spiritual journey](https://www.reddit.com/r/ChatGPT/comments/1k997xt/the_new_4o_is_the_most_misaligned_model_ever/).

It's interesting how all sci-fi writer got it fundamentally wrong: Artificial Intelligence are not robots with monotonous voices, or androids seeking to learn how to feel love - quite the contrary, we can design their emotions at will, to a degree where is _just about right_. From a certain angle, that's more dystopian than any of us ever imagined.


- - -
   

ğŸ‘¾
